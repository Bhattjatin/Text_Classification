{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86528d7d-59c2-4ba4-a814-70cd646e628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae4e44c-54a6-4328-8295-ac20d259735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the training and test data\n",
    "categories = None  # You can limit categories if needed\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74543f90-938f-4bf9-ab96-122b4ce67997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Initialize CountVectorizer with stop word removal\n",
    "count_vect = CountVectorizer(stop_words='english', min_df=2)\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_counts = count_vect.fit_transform(newsgroups_train.data)\n",
    "\n",
    "# Transform test data\n",
    "X_test_counts = count_vect.transform(newsgroups_test.data)\n",
    "\n",
    "# Apply TF-IDF transformation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee78612-8017-4e07-851b-ca14de3b1565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.20      0.32       319\n",
      "           1       0.65      0.69      0.67       389\n",
      "           2       0.66      0.60      0.63       394\n",
      "           3       0.61      0.74      0.67       392\n",
      "           4       0.78      0.68      0.72       385\n",
      "           5       0.81      0.76      0.79       395\n",
      "           6       0.78      0.78      0.78       390\n",
      "           7       0.81      0.73      0.77       396\n",
      "           8       0.85      0.75      0.80       398\n",
      "           9       0.91      0.80      0.85       397\n",
      "          10       0.57      0.93      0.71       399\n",
      "          11       0.64      0.79      0.70       396\n",
      "          12       0.71      0.53      0.61       393\n",
      "          13       0.88      0.76      0.81       396\n",
      "          14       0.76      0.74      0.75       394\n",
      "          15       0.38      0.92      0.54       398\n",
      "          16       0.57      0.72      0.64       364\n",
      "          17       0.82      0.79      0.80       376\n",
      "          18       0.87      0.30      0.45       310\n",
      "          19       1.00      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.68      7532\n",
      "   macro avg       0.74      0.66      0.65      7532\n",
      "weighted avg       0.73      0.68      0.67      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train model using sklearn's Naive Bayes\n",
    "clf_sklearn = MultinomialNB()\n",
    "clf_sklearn.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sklearn = clf_sklearn.predict(X_test_tfidf)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(newsgroups_test.target, y_pred_sklearn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a4bb94-0295-4063-859c-e6e39c86ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NaiveBayesFromScratch:\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.word_probs = {}\n",
    "        self.vocab = set()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Calculate class probabilities and word frequencies per class\n",
    "        self.classes = np.unique(y)\n",
    "        word_count = {}\n",
    "        class_count = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            class_count[c] = np.sum(y == c)\n",
    "            word_count[c] = {}\n",
    "\n",
    "        total_words_in_class = {c: 0 for c in self.classes}\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            label = y[i]\n",
    "            words = X[i].split()  # Assuming X[i] is preprocessed text\n",
    "            for word in words:\n",
    "                self.vocab.add(word)\n",
    "                if word not in word_count[label]:\n",
    "                    word_count[label][word] = 1\n",
    "                else:\n",
    "                    word_count[label][word] += 1\n",
    "                total_words_in_class[label] += 1\n",
    "\n",
    "        # Calculate probabilities\n",
    "        for c in self.classes:\n",
    "            self.class_probs[c] = math.log(class_count[c] / len(y))\n",
    "            self.word_probs[c] = {}\n",
    "            for word in self.vocab:\n",
    "                word_count_c = word_count[c].get(word, 0) + 1  # Laplace smoothing\n",
    "                self.word_probs[c][word] = math.log(word_count_c / (total_words_in_class[c] + len(self.vocab)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for doc in X:\n",
    "            doc_words = doc.split()  # Assuming X contains preprocessed text\n",
    "            class_scores = {}\n",
    "            for c in self.classes:\n",
    "                class_scores[c] = self.class_probs[c]\n",
    "                for word in doc_words:\n",
    "                    if word in self.vocab:\n",
    "                        class_scores[c] += self.word_probs[c].get(word, math.log(1 / (len(self.vocab))))\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fc3848-267e-49c5-b927-7152df84b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.07      0.13       319\n",
      "           1       0.68      0.34      0.46       389\n",
      "           2       0.52      0.03      0.06       394\n",
      "           3       0.54      0.52      0.53       392\n",
      "           4       0.79      0.23      0.35       385\n",
      "           5       0.48      0.78      0.60       395\n",
      "           6       0.90      0.45      0.60       390\n",
      "           7       0.85      0.21      0.33       396\n",
      "           8       0.89      0.15      0.25       398\n",
      "           9       0.93      0.27      0.42       397\n",
      "          10       0.47      0.56      0.51       399\n",
      "          11       0.26      0.72      0.39       396\n",
      "          12       0.73      0.18      0.29       393\n",
      "          13       0.80      0.45      0.57       396\n",
      "          14       0.72      0.41      0.53       394\n",
      "          15       0.23      0.92      0.36       398\n",
      "          16       0.51      0.23      0.32       364\n",
      "          17       0.21      0.81      0.34       376\n",
      "          18       0.30      0.33      0.31       310\n",
      "          19       0.50      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.39      7532\n",
      "   macro avg       0.60      0.38      0.37      7532\n",
      "weighted avg       0.61      0.39      0.38      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train custom Naive Bayes model\n",
    "clf_custom = NaiveBayesFromScratch()\n",
    "clf_custom.fit(newsgroups_train.data, newsgroups_train.target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_custom = clf_custom.predict(newsgroups_test.data)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(newsgroups_test.target, y_pred_custom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73548b4c-928a-4b51-b51f-270fb58e85ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sklearn Multinomial Naive Bayes ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.20      0.32       319\n",
      "           1       0.65      0.69      0.67       389\n",
      "           2       0.66      0.60      0.63       394\n",
      "           3       0.61      0.74      0.67       392\n",
      "           4       0.78      0.68      0.72       385\n",
      "           5       0.81      0.76      0.79       395\n",
      "           6       0.78      0.78      0.78       390\n",
      "           7       0.81      0.73      0.77       396\n",
      "           8       0.85      0.75      0.80       398\n",
      "           9       0.91      0.80      0.85       397\n",
      "          10       0.57      0.93      0.71       399\n",
      "          11       0.64      0.79      0.70       396\n",
      "          12       0.71      0.53      0.61       393\n",
      "          13       0.88      0.76      0.81       396\n",
      "          14       0.76      0.74      0.75       394\n",
      "          15       0.38      0.92      0.54       398\n",
      "          16       0.57      0.72      0.64       364\n",
      "          17       0.82      0.79      0.80       376\n",
      "          18       0.87      0.30      0.45       310\n",
      "          19       1.00      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.68      7532\n",
      "   macro avg       0.74      0.66      0.65      7532\n",
      "weighted avg       0.73      0.68      0.67      7532\n",
      "\n",
      "Sklearn Naive Bayes Accuracy: 0.6816250663834307\n",
      "\n",
      "=== Custom Naive Bayes Implementation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.07      0.13       319\n",
      "           1       0.68      0.34      0.46       389\n",
      "           2       0.52      0.03      0.06       394\n",
      "           3       0.54      0.52      0.53       392\n",
      "           4       0.79      0.23      0.35       385\n",
      "           5       0.48      0.78      0.60       395\n",
      "           6       0.90      0.45      0.60       390\n",
      "           7       0.85      0.21      0.33       396\n",
      "           8       0.89      0.15      0.25       398\n",
      "           9       0.93      0.27      0.42       397\n",
      "          10       0.47      0.56      0.51       399\n",
      "          11       0.26      0.72      0.39       396\n",
      "          12       0.73      0.18      0.29       393\n",
      "          13       0.80      0.45      0.57       396\n",
      "          14       0.72      0.41      0.53       394\n",
      "          15       0.23      0.92      0.36       398\n",
      "          16       0.51      0.23      0.32       364\n",
      "          17       0.21      0.81      0.34       376\n",
      "          18       0.30      0.33      0.31       310\n",
      "          19       0.50      0.01      0.02       251\n",
      "\n",
      "    accuracy                           0.39      7532\n",
      "   macro avg       0.60      0.38      0.37      7532\n",
      "weighted avg       0.61      0.39      0.38      7532\n",
      "\n",
      "Custom Naive Bayes Accuracy: 0.394583112055231\n",
      "\n",
      "=== Comparison of Results ===\n",
      "Sklearn Naive Bayes Accuracy: 0.6816250663834307\n",
      "Custom Naive Bayes Accuracy: 0.394583112055231\n",
      "There is a significant difference between the two implementations.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Sklearn Naive Bayes Predictions\n",
    "y_pred_sklearn = clf_sklearn.predict(X_test_tfidf)\n",
    "\n",
    "# Print classification report and accuracy for Sklearn implementation\n",
    "print(\"=== Sklearn Multinomial Naive Bayes ===\")\n",
    "print(classification_report(newsgroups_test.target, y_pred_sklearn))\n",
    "accuracy_sklearn = accuracy_score(newsgroups_test.target, y_pred_sklearn)\n",
    "print(f\"Sklearn Naive Bayes Accuracy: {accuracy_sklearn}\")\n",
    "\n",
    "# Custom Naive Bayes Predictions\n",
    "y_pred_custom = clf_custom.predict(newsgroups_test.data)\n",
    "\n",
    "# Print classification report and accuracy for custom implementation\n",
    "print(\"\\n=== Custom Naive Bayes Implementation ===\")\n",
    "print(classification_report(newsgroups_test.target, y_pred_custom))\n",
    "accuracy_custom = accuracy_score(newsgroups_test.target, y_pred_custom)\n",
    "print(f\"Custom Naive Bayes Accuracy: {accuracy_custom}\")\n",
    "\n",
    "# Compare results\n",
    "print(\"\\n=== Comparison of Results ===\")\n",
    "print(f\"Sklearn Naive Bayes Accuracy: {accuracy_sklearn}\")\n",
    "print(f\"Custom Naive Bayes Accuracy: {accuracy_custom}\")\n",
    "\n",
    "if abs(accuracy_sklearn - accuracy_custom) < 0.05:\n",
    "    print(\"Both implementations have approximately the same accuracy.\")\n",
    "else:\n",
    "    print(\"There is a significant difference between the two implementations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe5652-980e-443a-94ec-87ea43427e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
